{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import pinecone\n",
    "import requests\n",
    "import xmltodict\n",
    "from bs4 import BeautifulSoup\n",
    "from dotenv import load_dotenv\n",
    "from langchain import OpenAI\n",
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS, Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "from logger import logger\n",
    "from config import PINECONE_ENV"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(\"http://eugeneyan.com/sitemap.xml\")\n",
    "xml = r.text\n",
    "raw = xmltodict.parse(xml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = requests.get('https://eugeneyan.com/writing/content-moderation/').text\n",
    "soup = BeautifulSoup(html, features=\"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _paragraphs = soup.find_all('p')\n",
    "# _paragraphs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paragraphs = []\n",
    "\n",
    "# for p in _paragraphs:\n",
    "#     if'class' in p.attrs and 'date' in p['class']:\n",
    "#         continue\n",
    "#     if p.get_text() == 'To cite this content, please use:':\n",
    "#         break\n",
    "#     paragraphs.append(p.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lines = [line.strip() for line in paragraphs]\n",
    "# lines[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lines = [line for line in lines if len(line) > 15]\n",
    "# lines[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('\\n'.join(line for line in lines if line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from(url, min_line_length=20, last_paragraph='To cite this content, please use:'):\n",
    "    html = requests.get(url).text\n",
    "    soup = BeautifulSoup(html, features=\"html.parser\")\n",
    "    \n",
    "    # Find all paragraphs and exclude all paragraphs after the \"To cite this content, please use:\" paragraph\n",
    "    _paragraphs = soup.find_all('p')\n",
    "    \n",
    "    paragraphs = []\n",
    "    for p in _paragraphs:\n",
    "        if'class' in p.attrs and 'date' in p['class']:\n",
    "            continue\n",
    "        if p.get_text() == last_paragraph:\n",
    "            break\n",
    "        paragraphs.append(p.get_text())\n",
    "    logger.debug(f'Paragraphs: {paragraphs[0]}')\n",
    "    \n",
    "    # Remove consecutive newlines\n",
    "    lines = (line.strip() for line in paragraphs)\n",
    "    \n",
    "    # Remove lines that are less than 10 characters\n",
    "    lines = (line for line in lines if len(line) > min_line_length)\n",
    "    \n",
    "    return '\\n'.join(line for line in lines if line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How can we improve a machine learning project’s chance of success? Over the years, I’ve explored various mechanisms in both my own projects and those of my team members. Most people who tried these mechanisms ended up adopting them in future projects.\n",
      "While these mechanisms were developed with machine learning projects in mind, with a few tweaks, they can be applied to other technical endeavors too.\n",
      "If your team is like most teams I’ve been on, you have 2 - 3 problems for every available person. Thus, each member works on 1 or 2 problems simultaneously, with some folks taking 3 or more. And because everyone’s so busy, we barely have time to check in on each other’s projects outside of standup, planning, retrospective, etc.\n",
      "This is an anti-pattern. It can lead to a project going off-track for months, or a critical error (e.g., incorrect training data, invalid train-validation split) going undetected until late in the implementation phase.\n",
      "One solution is to have a pilot and copilot for each project. The pilot is the main project owner and is in charge of its success (or failure). They own and delegate the work as required though they’re usually responsible for the bulk of design and critical code paths.\n",
      "The copilot helps the pilot stay on track, identify critical flaws, and call out blindspots. This includes periodic check-ins, reviewing document drafts and prototypes, and being a mandatory code reviewer. For example, the copilot should challenge the pilot if the proposed design doesn’t solve the business problem, or if the train-validation split is invalid. To be able to spot these issues, the copilot typically has experience in the problem space, or has more experience in general, similar to how senior engineers guide juniors.\n",
      "For every 10 hours the pilot spends on the project, the copilot can expect to spend an hour on reviews (10% of the pilot’s effort). While this may seem excessive, copilots have helped avoid costlier rework or abandoning a project due to mistakes that snowballed.\n",
      "Pilots and copilots don’t have to be from the same job family. As an applied scientist, I often partner with an engineer who helps with infrastructure, observability, CI/CD, etc. If both scientist and engineer are sufficiently experienced, they can double up as each other’s copilot. As they review each other’s work, knowledge transfer occurs organically and they learn to be effective copilots for other engineers or scientists in future projects.\n",
      "Also read more on the dangers of flying solo by Ethan Rosenthal and Vicki Boykis.\n",
      "In my earlier projects, because I was overeager, I would immediately jump into the data and begin training models. After watching me go in the wrong direction for a week or two, a merciful senior would share a paper, casually suggesting that it might be helpful to read it. It always was. After letting this happen once too often, I finally learned to start my projects with a literature review.\n",
      "For a literature review, I read papers relevant to the problem. I’m biased towards solutions that have been applied in industry though more academic papers have also been helpful.\n",
      "While reading these papers, I’m less interested in model architecture and focus on:\n",
      "To quickly go through the papers, I adopt the three-pass approach.\n",
      "This is similar to a code review but for machine learning prototypes and experiments. Once I have initial experiment results, I schedule a review with fellow scientists to ensure I haven’t overlooked any blindspots or committed critical errors.\n",
      "During the review, I focus on understanding the methodology and the potential of the current approach. Some questions include:\n",
      "To conduct methodology reviews asynchronously, like a code review, we could adopt a tool like DagsHub which supports comments on Jupyter notebooks and data.\n",
      "To tie it all together, we timebox each project phase and task. Time constraints help us focus on the most important tasks and not get bogged down in the details. Timeboxing for machine learning projects can be challenging, because compared to engineering projects, the work is relatively ill-defined. Furthermore, a large part of the work is research and experimentation which unfortunately leads to many a dead end.\n",
      "But it’s because of these challenges that timeboxing is effective—how much effort should we invest before pivoting? In most industry settings, we don’t have limitless resources to pursue a problem for years.\n",
      "(I treat timeboxes differently from estimates. Timeboxes are stretch goals while estimates are project management inputs that indicate the upper bound of effort needed. To convert timeboxes to estimates, I usually multiply by 1.5 - 3.0.)\n",
      "Here are three ways to define timeboxes.\n",
      "The first—and most aggressive—approach is to take the time spent on similar projects and halve it. This forces us to be scrappy and build a minimum lovable product that we can quickly get feedback on, reducing the iteration cycle. This approach works well in startups and startup-like teams though it can be too intense to adopt all the time.\n",
      "A less extreme approach is to set a timebox that is “comfortable yet challenging”. Thus, instead of halving the timebox, we reduce it by 10 - 20%. By deliberately introducing these constraints, we give ourselves the opportunity to reflect on timesinks to avoid and how to achieve more with fewer resources. This is a good default for most seasoned teams.\n",
      "Finally, for greenfield projects that may be hard to scope, we can adopt standard timeboxes. For example, we might allocate two weeks for a literature review, four to eight weeks to build a prototype, and three to six months to implement it in production.\n",
      "I’ve also written about other mechanisms for machine learning projects, including:\n",
      "What mechanisms do you adopt in your machine learning projects? Please share below!\n",
      "Thanks to Yang Xinyi for reading drafts of this.\n"
     ]
    }
   ],
   "source": [
    "print(extract_text_from('https://eugeneyan.com/writing/mechanisms-for-projects/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = []\n",
    "\n",
    "for info in raw['urlset']['url']:\n",
    "    url = info['loc']\n",
    "    if 'https://eugeneyan.com/writing/' in info['loc']:\n",
    "        pages.append({'text': extract_text_from(url), 'url': url})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(pages)\n",
    "\n",
    "# # Exclude short posts that may be talks and mostly images\n",
    "df['text_len'] = df['text'].apply(lambda x: len(x))\n",
    "df = df[df['text_len'] > 500]\n",
    "df = df.drop(columns=['text_len'])\n",
    "\n",
    "# Exclude certain urls\n",
    "excluded_urls = {''}\n",
    "df = df[~df['url'].isin(excluded_urls)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet('../data/eugeneyan.parquet', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split each page into documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-26 17:06:54,129 - Split https://eugeneyan.com/writing/llm-bio/ into 10 docs\n",
      "2023-03-26 17:06:54,131 - Split https://eugeneyan.com/writing/labeling-guidelines/ into 5 docs\n",
      "2023-03-26 17:06:54,133 - Split https://eugeneyan.com/writing/content-moderation/ into 14 docs\n",
      "2023-03-26 17:06:54,134 - Split https://eugeneyan.com/writing/mechanisms-for-teams/ into 6 docs\n",
      "2023-03-26 17:06:54,134 - Split https://eugeneyan.com/writing/mechanisms-for-projects/ into 5 docs\n",
      "2023-03-26 17:06:54,135 - Split https://eugeneyan.com/writing/roam-to-obsidian/ into 2 docs\n",
      "2023-03-26 17:06:54,135 - Split https://eugeneyan.com/writing/getting-help/ into 3 docs\n",
      "2023-03-26 17:06:54,136 - Split https://eugeneyan.com/writing/2022-in-review/ into 6 docs\n",
      "2023-03-26 17:06:54,137 - Split https://eugeneyan.com/writing/autoencoders-vs-diffusers/ into 3 docs\n",
      "2023-03-26 17:06:54,138 - Split https://eugeneyan.com/writing/text-to-image/ into 16 docs\n",
      "2023-03-26 17:06:54,138 - Split https://eugeneyan.com/writing/recsys2022/ into 14 docs\n",
      "2023-03-26 17:06:54,139 - Split https://eugeneyan.com/writing/testing-pipelines/ into 10 docs\n",
      "2023-03-26 17:06:54,140 - Split https://eugeneyan.com/writing/simplicity/ into 6 docs\n",
      "2023-03-26 17:06:54,141 - Split https://eugeneyan.com/writing/uncommon-python/ into 7 docs\n",
      "2023-03-26 17:06:54,141 - Split https://eugeneyan.com/writing/15-5/ into 2 docs\n",
      "2023-03-26 17:06:54,142 - Split https://eugeneyan.com/writing/design-patterns/ into 7 docs\n",
      "2023-03-26 17:06:54,142 - Split https://eugeneyan.com/writing/onboarding/ into 9 docs\n",
      "2023-03-26 17:06:54,143 - Split https://eugeneyan.com/writing/bandits/ into 14 docs\n",
      "2023-03-26 17:06:54,144 - Split https://eugeneyan.com/writing/position-bias/ into 6 docs\n",
      "2023-03-26 17:06:54,145 - Split https://eugeneyan.com/writing/counterfactual-evaluation/ into 8 docs\n",
      "2023-03-26 17:06:54,146 - Split https://eugeneyan.com/writing/intent-vs-requirements/ into 7 docs\n",
      "2023-03-26 17:06:54,147 - Split https://eugeneyan.com/writing/project-quick-start/ into 8 docs\n",
      "2023-03-26 17:06:54,148 - Split https://eugeneyan.com/writing/becoming-a-data-leader/ into 2 docs\n",
      "2023-03-26 17:06:54,149 - Split https://eugeneyan.com/writing/red-flags/ into 6 docs\n",
      "2023-03-26 17:06:54,149 - Split https://eugeneyan.com/writing/how-to-keep-learning/ into 5 docs\n",
      "2023-03-26 17:06:54,150 - Split https://eugeneyan.com/writing/2021-year-in-review/ into 6 docs\n",
      "2023-03-26 17:06:54,151 - Split https://eugeneyan.com/writing/applyingml/ into 1 docs\n",
      "2023-03-26 17:06:54,152 - Split https://eugeneyan.com/writing/what-i-learned-from-writing-online-susan-shu/ into 4 docs\n",
      "2023-03-26 17:06:54,152 - Split https://eugeneyan.com/writing/what-i-learned-from-writing-online/ into 6 docs\n",
      "2023-03-26 17:06:54,153 - Split https://eugeneyan.com/writing/recsys2021/ into 5 docs\n",
      "2023-03-26 17:06:54,154 - Split https://eugeneyan.com/writing/first-rule-of-ml/ into 6 docs\n",
      "2023-03-26 17:06:54,155 - Split https://eugeneyan.com/writing/reinforcement-learning-for-recsys-and-search/ into 12 docs\n",
      "2023-03-26 17:06:54,155 - Split https://eugeneyan.com/writing/bootstrapping-data-labels/ into 11 docs\n",
      "2023-03-26 17:06:54,156 - Split https://eugeneyan.com/writing/mailbag-bootstrap-relevant-docs/ into 2 docs\n",
      "2023-03-26 17:06:54,157 - Split https://eugeneyan.com/writing/influencing-without-authority/ into 8 docs\n",
      "2023-03-26 17:06:54,158 - Split https://eugeneyan.com/writing/system-design-for-discovery/ into 12 docs\n",
      "2023-03-26 17:06:54,159 - Split https://eugeneyan.com/writing/patterns-for-personalization/ into 24 docs\n",
      "2023-03-26 17:06:54,159 - Split https://eugeneyan.com/writing/machine-learning-metagame/ into 11 docs\n",
      "2023-03-26 17:06:54,160 - Split https://eugeneyan.com/writing/search-query-matching/ into 18 docs\n",
      "2023-03-26 17:06:54,161 - Split https://eugeneyan.com/writing/imposter-syndrome-susan/ into 6 docs\n",
      "2023-03-26 17:06:54,162 - Split https://eugeneyan.com/writing/imposter-syndrome/ into 8 docs\n",
      "2023-03-26 17:06:54,162 - Split https://eugeneyan.com/writing/values-and-superpowers/ into 8 docs\n",
      "2023-03-26 17:06:54,163 - Split https://eugeneyan.com/writing/how-to-choose-problems/ into 11 docs\n",
      "2023-03-26 17:06:54,164 - Split https://eugeneyan.com/writing/seven-habits-that-shaped-my-decade/ into 13 docs\n",
      "2023-03-26 17:06:54,165 - Split https://eugeneyan.com/writing/ml-design-docs/ into 14 docs\n",
      "2023-03-26 17:06:54,166 - Split https://eugeneyan.com/writing/writing-docs-why-what-how/ into 9 docs\n",
      "2023-03-26 17:06:54,167 - Split https://eugeneyan.com/writing/feature-stores/ into 15 docs\n",
      "2023-03-26 17:06:54,168 - Split https://eugeneyan.com/writing/how-to-win-data-hackathon/ into 5 docs\n",
      "2023-03-26 17:06:54,169 - Split https://eugeneyan.com/writing/data-science-teams/ into 14 docs\n",
      "2023-03-26 17:06:54,170 - Split https://eugeneyan.com/writing/you-dont-need-another-mooc/ into 7 docs\n",
      "2023-03-26 17:06:54,171 - Split https://eugeneyan.com/writing/mailbag-resume-for-experienced-ds/ into 3 docs\n",
      "2023-03-26 17:06:54,173 - Split https://eugeneyan.com/writing/real-time-recommendations/ into 17 docs\n",
      "2023-03-26 17:06:54,174 - Split https://eugeneyan.com/writing/2021-roadmap/ into 3 docs\n",
      "2023-03-26 17:06:54,174 - Split https://eugeneyan.com/writing/retrospective-2020/ into 6 docs\n",
      "2023-03-26 17:06:54,175 - Split https://eugeneyan.com/writing/flying-dagger/ into 2 docs\n",
      "2023-03-26 17:06:54,176 - Split https://eugeneyan.com/writing/how-i-reflect-and-plan/ into 2 docs\n",
      "2023-03-26 17:06:54,177 - Split https://eugeneyan.com/writing/informal-mentors-alexey-grigorev/ into 17 docs\n",
      "2023-03-26 17:06:54,178 - Split https://eugeneyan.com/writing/mailbag-blog-architecture/ into 1 docs\n",
      "2023-03-26 17:06:54,179 - Split https://eugeneyan.com/writing/life-lessons-from-machine-learning/ into 10 docs\n",
      "2023-03-26 17:06:54,180 - Split https://eugeneyan.com/writing/role-title-mismatch/ into 6 docs\n",
      "2023-03-26 17:06:54,181 - Split https://eugeneyan.com/writing/data-science-roles/ into 9 docs\n",
      "2023-03-26 17:06:54,182 - Split https://eugeneyan.com/writing/informal-mentors-chip-huyen/ into 8 docs\n",
      "2023-03-26 17:06:54,183 - Split https://eugeneyan.com/writing/data-discovery-platforms/ into 12 docs\n",
      "2023-03-26 17:06:54,184 - Split https://eugeneyan.com/writing/netlify-back-to-github-pages/ into 2 docs\n",
      "2023-03-26 17:06:54,185 - Split https://eugeneyan.com/writing/data-science-portfolio-how-why-what/ into 13 docs\n",
      "2023-03-26 17:06:54,186 - Split https://eugeneyan.com/writing/how-to-install-scann-on-mac/ into 2 docs\n",
      "2023-03-26 17:06:54,186 - Split https://eugeneyan.com/writing/prototyping-to-get-buy-in/ into 6 docs\n",
      "2023-03-26 17:06:54,187 - Split https://eugeneyan.com/writing/writing-and-coding/ into 11 docs\n",
      "2023-03-26 17:06:54,188 - Split https://eugeneyan.com/writing/recsys2020/ into 11 docs\n",
      "2023-03-26 17:06:54,189 - Split https://eugeneyan.com/writing/present/ into 1 docs\n",
      "2023-03-26 17:06:54,190 - Split https://eugeneyan.com/writing/favorite-productivity-coffee-routines-habits/ into 12 docs\n",
      "2023-03-26 17:06:54,191 - Split https://eugeneyan.com/writing/how-to-accomplish-more-with-less/ into 9 docs\n",
      "2023-03-26 17:06:54,191 - Split https://eugeneyan.com/writing/migrating-to-utterances/ into 1 docs\n",
      "2023-03-26 17:06:54,192 - Split https://eugeneyan.com/writing/testing-ml/ into 6 docs\n",
      "2023-03-26 17:06:54,193 - Split https://eugeneyan.com/writing/mailbag-pdf-fields/ into 3 docs\n",
      "2023-03-26 17:06:54,193 - Split https://eugeneyan.com/writing/why-read-papers/ into 5 docs\n",
      "2023-03-26 17:06:54,194 - Split https://eugeneyan.com/writing/mailbag-senior-ds/ into 2 docs\n",
      "2023-03-26 17:06:54,195 - Split https://eugeneyan.com/writing/beginners-mind/ into 9 docs\n",
      "2023-03-26 17:06:54,196 - Split https://eugeneyan.com/writing/nlp-supervised-learning-survey/ into 17 docs\n",
      "2023-03-26 17:06:54,197 - Split https://eugeneyan.com/writing/end-to-end-data-science/ into 14 docs\n",
      "2023-03-26 17:06:54,198 - Split https://eugeneyan.com/writing/fastapi-html-checkbox-download/ into 2 docs\n",
      "2023-03-26 17:06:54,199 - Split https://eugeneyan.com/writing/what-i-did-not-learn-about-writing-in-school/ into 8 docs\n",
      "2023-03-26 17:06:54,200 - Split https://eugeneyan.com/writing/georgia-tech-omscs-faq/ into 13 docs\n",
      "2023-03-26 17:06:54,200 - Split https://eugeneyan.com/writing/how-to-set-up-html-app-with-fastapi-jinja-forms-templates/ into 1 docs\n",
      "2023-03-26 17:06:54,201 - Split https://eugeneyan.com/writing/why-you-need-to-follow-up-after-your-data-science-project/ into 8 docs\n",
      "2023-03-26 17:06:54,202 - Split https://eugeneyan.com/writing/what-i-do-during-a-data-science-project-to-ensure-success/ into 5 docs\n",
      "2023-03-26 17:06:54,203 - Split https://eugeneyan.com/writing/how-to-update-github-profile-readme-automatically/ into 2 docs\n",
      "2023-03-26 17:06:54,204 - Split https://eugeneyan.com/writing/when-giving-your-100-gets-you-less-than-85/ into 2 docs\n",
      "2023-03-26 17:06:54,205 - Split https://eugeneyan.com/writing/notes-from-sparkai-summit-application-specific/ into 11 docs\n",
      "2023-03-26 17:06:54,207 - Split https://eugeneyan.com/writing/notes-from-sparkai-summit-application-agnostic/ into 7 docs\n",
      "2023-03-26 17:06:54,239 - Split https://eugeneyan.com/writing/setting-up-python-project-for-automation-and-collaboration/ into 10 docs\n",
      "2023-03-26 17:06:54,240 - Split https://eugeneyan.com/writing/mailbag-ds-requirements/ into 2 docs\n",
      "2023-03-26 17:06:54,247 - Split https://eugeneyan.com/writing/why-airflow-jobs-one-day-late/ into 2 docs\n",
      "2023-03-26 17:06:54,258 - Split https://eugeneyan.com/writing/what-i-do-before-a-data-science-project-to-ensure-success/ into 11 docs\n",
      "2023-03-26 17:06:54,260 - Split https://eugeneyan.com/writing/what-i-love-about-scrum-for-data-science/ into 8 docs\n",
      "2023-03-26 17:06:54,261 - Split https://eugeneyan.com/writing/how-to-apply-crockers-law-for-feedback-and-growth/ into 6 docs\n",
      "2023-03-26 17:06:54,261 - Split https://eugeneyan.com/writing/practical-guide-to-maintaining-machine-learning/ into 12 docs\n",
      "2023-03-26 17:06:54,262 - Split https://eugeneyan.com/writing/challenges-after-deploying-machine-learning/ into 12 docs\n",
      "2023-03-26 17:06:54,263 - Split https://eugeneyan.com/writing/how-to-write-david-x-sahil/ into 4 docs\n",
      "2023-03-26 17:06:54,264 - Split https://eugeneyan.com/writing/evaluating-ideas-at-a-hackathon/ into 6 docs\n",
      "2023-03-26 17:06:54,265 - Split https://eugeneyan.com/writing/serendipity-and-accuracy-in-recommender-systems/ into 9 docs\n",
      "2023-03-26 17:06:54,266 - Split https://eugeneyan.com/writing/how-to-give-a-kick-ass-data-science-talk/ into 6 docs\n",
      "2023-03-26 17:06:54,267 - Split https://eugeneyan.com/writing/commando-soldier-police-and-your-career/ into 5 docs\n",
      "2023-03-26 17:06:54,268 - Split https://eugeneyan.com/writing/note-taking-zettelkasten/ into 5 docs\n",
      "2023-03-26 17:06:54,269 - Split https://eugeneyan.com/writing/reading-note-taking-writing/ into 5 docs\n",
      "2023-03-26 17:06:54,270 - Split https://eugeneyan.com/writing/experimentation-workflow-with-jupyter-papermill-mlflow/ into 5 docs\n",
      "2023-03-26 17:06:54,271 - Split https://eugeneyan.com/writing/psych-grad-to-data-science-lead/ into 10 docs\n",
      "2023-03-26 17:06:54,272 - Split https://eugeneyan.com/writing/recommender-systems-graph-and-nlp-pytorch/ into 15 docs\n",
      "2023-03-26 17:06:54,272 - Split https://eugeneyan.com/writing/recommender-systems-baseline-pytorch/ into 11 docs\n",
      "2023-03-26 17:06:54,273 - Split https://eugeneyan.com/writing/omscs-cs6200-introduction-to-operating-systems/ into 7 docs\n",
      "2023-03-26 17:06:54,274 - Split https://eugeneyan.com/writing/omscs-cs6750-human-computer-interaction/ into 7 docs\n",
      "2023-03-26 17:06:54,275 - Split https://eugeneyan.com/writing/goodbye-wordpress-hello-jekyll into 1 docs\n",
      "2023-03-26 17:06:54,276 - Split https://eugeneyan.com/writing/omscs-cs6440-intro-to-health-informatics/ into 7 docs\n",
      "2023-03-26 17:06:54,277 - Split https://eugeneyan.com/writing/omscs-cs7646-machine-learning-for-trading/ into 7 docs\n",
      "2023-03-26 17:06:54,278 - Split https://eugeneyan.com/writing/what-does-a-data-scientist-really-do/ into 5 docs\n",
      "2023-03-26 17:06:54,279 - Split https://eugeneyan.com/writing/data-science-and-agile-frameworks-for-effectiveness/ into 13 docs\n",
      "2023-03-26 17:06:54,280 - Split https://eugeneyan.com/writing/data-science-and-agile-what-works-and-what-doesnt/ into 10 docs\n",
      "2023-03-26 17:06:54,281 - Split https://eugeneyan.com/writing/omscs-cs6601-artificial-intelligence/ into 7 docs\n",
      "2023-03-26 17:06:54,282 - Split https://eugeneyan.com/writing/omscs-cs6460-education-technology/ into 8 docs\n",
      "2023-03-26 17:06:54,283 - Split https://eugeneyan.com/writing/omscs-cs7642-reinforcement-learning/ into 6 docs\n",
      "2023-03-26 17:06:54,284 - Split https://eugeneyan.com/writing/building-a-strong-data-science-team-culture/ into 3 docs\n",
      "2023-03-26 17:06:54,286 - Split https://eugeneyan.com/writing/omscs-cs7641-machine-learning/ into 4 docs\n",
      "2023-03-26 17:06:54,287 - Split https://eugeneyan.com/writing/my-first-100-days-as-data-science-lead/ into 4 docs\n",
      "2023-03-26 17:06:54,288 - Split https://eugeneyan.com/writing/omscs-cs6300-software-development-process/ into 5 docs\n",
      "2023-03-26 17:06:54,289 - Split https://eugeneyan.com/writing/how-to-get-started-in-data-science/ into 7 docs\n",
      "2023-03-26 17:06:54,290 - Split https://eugeneyan.com/writing/omscs-cs6476-computer-vision/ into 5 docs\n",
      "2023-03-26 17:06:54,290 - Split https://eugeneyan.com/writing/one-way-to-help-a-data-science-team-succeed/ into 2 docs\n",
      "2023-03-26 17:06:54,291 - Split https://eugeneyan.com/writing/product-categorization-api-part-3-creating-an-api/ into 4 docs\n",
      "2023-03-26 17:06:54,292 - Split https://eugeneyan.com/writing/image-search-is-now-live/ into 2 docs\n",
      "2023-03-26 17:06:54,293 - Split https://eugeneyan.com/writing/product-categorization-api-part-2-data-preparation/ into 5 docs\n",
      "2023-03-26 17:06:54,294 - Split https://eugeneyan.com/writing/image-categorization-is-now-live/ into 1 docs\n",
      "2023-03-26 17:06:54,295 - Split https://eugeneyan.com/writing/im-going-back-to-school/ into 4 docs\n",
      "2023-03-26 17:06:54,295 - Split https://eugeneyan.com/writing/sortmyskills-is-now-live/ into 3 docs\n",
      "2023-03-26 17:06:54,296 - Split https://eugeneyan.com/writing/product-categorization-api-part-1-data-acquisition-and-formatting/ into 5 docs\n",
      "2023-03-26 17:06:54,297 - Split https://eugeneyan.com/writing/thoughts-on-functional-programming-in-scala-course-coursera/ into 3 docs\n",
      "2023-03-26 17:06:54,298 - Split https://eugeneyan.com/writing/first-post/ into 1 docs\n",
      "2023-03-26 17:06:54,298 - Split https://eugeneyan.com/writing/datakind-sg-project-accelerator/ into 9 docs\n",
      "2023-03-26 17:06:54,300 - Split https://eugeneyan.com/writing/ into 15 docs\n"
     ]
    }
   ],
   "source": [
    "text_splitter = CharacterTextSplitter(chunk_size=1500, separator='\\n')\n",
    "\n",
    "docs, metadata = [], []\n",
    "\n",
    "for page in pages:\n",
    "    splits = text_splitter.split_text(page['text'])\n",
    "    # for split in splits:\n",
    "    #     docs.append(split)\n",
    "    #     metadata.append({'source': split, 'url': page['url']})\n",
    "    docs.extend(splits)\n",
    "    metadata.extend([{'source': page['url']}] * len(splits))  # This Q&A chain relies on the url being in the 'source' key\n",
    "    logger.info(f'Split {page[\"url\"]} into {len(splits)} docs')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a FAISS vector store for offline prototyping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = FAISS.from_texts(docs, OpenAIEmbeddings(), metadatas=metadata)\n",
    "with open('../data/faiss_store.pkl', 'wb') as f:\n",
    "    pickle.dump(store, f)  # This is a 10mb file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "# question = 'Question for eugeneyan.com: Why is writing important?'\n",
    "\n",
    "# with open('../data/faiss_store.pkl', 'rb') as f:\n",
    "#     store = pickle.load(open('../data/faiss_store.pkl', 'rb'))\n",
    "\n",
    "# chain = load_qa_with_sources_chain(ChatOpenAI(temperature=0), verbose=False)\n",
    "# response = chain({'input_documents': store.similarity_search(question, 4), \n",
    "#                   'question': question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # VectorDBQAWithSourcesChain is DEPRECATED\n",
    "\n",
    "# question = 'Question for eugeneyan.com: Why is writing important?'\n",
    "\n",
    "# with open('../data/faiss_store.pkl', 'rb') as f:\n",
    "#     store = pickle.load(open('../data/faiss_store.pkl', 'rb'))\n",
    "\n",
    "# llm=ChatOpenAI(temperature=0)\n",
    "# chain = VectorDBQAWithSourcesChain.from_chain_type(llm, chain_type='stuff', vectorstore=store)\n",
    "# response = chain({'question': question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this instead of load_qa_with_sources_chain for more control\n",
    "question = 'Question for eugeneyan.com: What is content moderation?'\n",
    "\n",
    "with open('../data/faiss_store.pkl', 'rb') as f:\n",
    "    store = pickle.load(open('../data/faiss_store.pkl', 'rb'))\n",
    "\n",
    "llm=OpenAI(temperature=0)\n",
    "chain = RetrievalQAWithSourcesChain.from_chain_type(llm, chain_type='stuff', retriever=store.as_retriever(), return_source_documents=True)\n",
    "response = chain({'question': question}, return_only_outputs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Question for eugeneyan.com: What is content moderation?',\n",
       " 'answer': ' Content moderation is the process of learning and inferring the quality of human-generated content such as product reviews, social media posts, and ads. It involves collecting a set of ground truth, using supervised ML models, and applying heuristics and unsupervised models.\\n',\n",
       " 'sources': 'https://eugeneyan.com/writing/content-moderation/',\n",
       " 'source_documents': [Document(page_content='Content moderation is the process of learning and inferring the quality of human-generated content such as product reviews, social media posts, and ads. How do we know which are irrelevant, incorrect, or downright harmful? A related problem is detecting anomalous activity such as fraudulent transactions or malicious traffic.\\nTo learn more about building robust content moderation systems, I dug into industry papers and tech blogs on classification, anomaly detection, and search relevance. Here are five patterns I observed:\\nRegardless of whether a heuristic-based, supervised, or unsupervised solution is adopted, we typically start with collecting a set of ground truth. This ground truth can then be used to train supervised ML models as well as evaluate the performance of heuristics and unsupervised models. The ground truth also acts as seed data to bootstrap more labels via active or semi-supervised learning.\\nThe most straightforward way to collect ground truth is to ask users. For Stack Exchange to block spam on their sites, a valuable data source is users flagging posts as spam. These flags were then used to identify and act on spammy users by blocking or rate-limiting them. They were also used as training data for machine learning models.', lookup_str='', metadata={'source': 'https://eugeneyan.com/writing/content-moderation/'}, lookup_index=0),\n",
       "  Document(page_content='Community Engagement:\\nEugene is passionate about fostering a strong data science community. He is an organizer and mentor for the Data Science Global Impact Challenge, a competition that encourages participants to use data science techniques to address pressing global issues. He is also involved in the AI Singapore initiative, which aims to promote AI and data science in Singapore.\\nIn summary, Eugene Yan is an experienced data scientist and machine learning practitioner known for his work in search and recommendation systems. Through his various roles, writing, and speaking engagements,and mentorship, he has contributed significantly to the field of data science and continues to share his knowledge with the community.\\nThe overall theme seems correct, though it got many details wrong, including:\\nEugene Yan, also known as @eugeneyan, is a data scientist, writer, and entrepreneur based in Singapore. He is widely recognized for his contributions to the data science community, including his popular blog, eugeneyan.com, where he shares insights on data science, machine learning, and personal growth.\\nEugene holds a Bachelor’s degree in Electrical and Electronic Engineering from the National University of Singapore, as well as a Master’s degree in Management Science and Engineering from Stanford University. After completing his studies, he worked at several tech companies, including Google, where he served as a software engineer.', lookup_str='', metadata={'source': 'https://eugeneyan.com/writing/llm-bio/'}, lookup_index=0),\n",
       "  Document(page_content='I think a lot about machine learning. And I think a lot about life. Sometimes, the channels mix and I find certain lessons from machine learning applicable to life.\\nHere are seven lessons. While I assume most readers are familiar with these machine learning concepts, I begin each lesson with a brief explanation.\\nWe clean data so our downstream analysis or machine learning is correct. As Randy Au shares, data cleaning isn’t grunt work; it is the work.\\nWe don’t use data without exploring and cleaning it. Similarly, we shouldn’t consume life’s inputs without assessing and filtering them.\\nTake food for example. How often do we reach for what’s widely available and easy to prepare? Until a few years ago, I was happily munching on a bowl of Sugary-Os cereal daily. Now that I’m more aware of my family’s history with diabetes, I’m more selective and pay greater attention to nutritional content. Also, as age catches up and my metabolism slows, I have to make a conscious effort to eat healthier and avoid junk food.\\nSugar is \"good\" for you (source)\\nIt’s the same with content. News outlets and social media rank information based on virality and advertising dollars. “Empty calorie info-bites” that are easy to consume—but don’t enrich us—circulate faster. Misinformation is rampant. Some content is in poor taste and downright toxic, and attempts to engage don’t end well. For sanity’s sake, just filter it out. Curate your news sources and who you follow on social media.', lookup_str='', metadata={'source': 'https://eugeneyan.com/writing/life-lessons-from-machine-learning/'}, lookup_index=0),\n",
       "  Document(page_content='Stack Exchange has several layers of defense against spam. The first line of defense is triggered when a spammer posts too often to be humanly possible. The spammer is hit with an HTTP 429 Error (Too Many Requests) and blocked or rate-limited.\\nThe second line of defense is based on heuristics. Specifically, they run posts through an “unholy amount of regular expressions” and some rules. If a post is caught, it is sent to users to check and potentially flag it as spam. If six users flag it as spam (six flags lol), the post is marked as spam and the user is blocked, rate-limited, or prevented from posting.\\nThe final line of defense is a (machine learning?) system that identifies posts most likely to be spam. They shadow-tested it and found it to be extremely accurate. It was catching almost all of the blatantly obvious spam. Eventually, this system was armed to cast three automatic flags and it drastically reduced the time to spam post deletion.\\nTime till spam deletion drops from no auto-flag (red) to 1 auto-flag (green) to 3 auto-flags (orange)\\nCloudflare also combines heuristics and machine learning (and other techniques) to identify bot traffic. They shared a comparison: If machine learning inference requires ~50ms, then hundreds of heuristics can be applied at ~20ms.', lookup_str='', metadata={'source': 'https://eugeneyan.com/writing/content-moderation/'}, lookup_index=0)]}"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-26 17:14:41,484 - Question: Question for eugeneyan.com: What is content moderation?\n",
      "2023-03-26 17:14:41,486 - Answer:  Content moderation is the process of learning and inferring the quality of human-generated content such as product reviews, social media posts, and ads. It involves collecting a set of ground truth, using supervised ML models, and applying heuristics and unsupervised models.\n",
      "\n",
      "2023-03-26 17:14:41,488 - Sources: https://eugeneyan.com/writing/content-moderation/\n",
      "2023-03-26 17:14:41,489 - URL: https://eugeneyan.com/writing/content-moderation/\n",
      "\n",
      "2023-03-26 17:14:41,491 - Source: Content moderation is the process of learning and inferring the quality of human-generated content such as product reviews, social media posts, and ads. How do we know which are irrelevant, incorrect, or downright harmful? A related problem is detecting anomalous activity such as fraudulent transactions or malicious traffic.\n",
      "To learn more about building robust content moderation systems, I dug into industry papers and tech blogs on classification, anomaly detection, and search relevance. Here are five patterns I observed:\n",
      "Regardless of whether a heuristic-based, supervised, or unsupervised solution is adopted, we typically start with collecting a set of ground truth. This ground truth can then be used to train supervised ML models as well as evaluate the performance of heuristics and unsupervised models. The ground truth also acts as seed data to bootstrap more labels via active or semi-supervised learning.\n",
      "The most straightforward way to collect ground truth is to ask users. For Stack Exchange to block spam on their sites, a valuable data source is users flagging posts as spam. These flags were then used to identify and act on spammy users by blocking or rate-limiting them. They were also used as training data for machine learning models.\n",
      "\n",
      "2023-03-26 17:14:41,492 - =====================\n",
      "2023-03-26 17:14:41,493 - URL: https://eugeneyan.com/writing/content-moderation/\n",
      "\n",
      "2023-03-26 17:14:41,494 - Source: Stack Exchange has several layers of defense against spam. The first line of defense is triggered when a spammer posts too often to be humanly possible. The spammer is hit with an HTTP 429 Error (Too Many Requests) and blocked or rate-limited.\n",
      "The second line of defense is based on heuristics. Specifically, they run posts through an “unholy amount of regular expressions” and some rules. If a post is caught, it is sent to users to check and potentially flag it as spam. If six users flag it as spam (six flags lol), the post is marked as spam and the user is blocked, rate-limited, or prevented from posting.\n",
      "The final line of defense is a (machine learning?) system that identifies posts most likely to be spam. They shadow-tested it and found it to be extremely accurate. It was catching almost all of the blatantly obvious spam. Eventually, this system was armed to cast three automatic flags and it drastically reduced the time to spam post deletion.\n",
      "Time till spam deletion drops from no auto-flag (red) to 1 auto-flag (green) to 3 auto-flags (orange)\n",
      "Cloudflare also combines heuristics and machine learning (and other techniques) to identify bot traffic. They shared a comparison: If machine learning inference requires ~50ms, then hundreds of heuristics can be applied at ~20ms.\n",
      "\n",
      "2023-03-26 17:14:41,495 - =====================\n"
     ]
    }
   ],
   "source": [
    "logger.info(f'Question: {response[\"question\"]}')\n",
    "logger.info(f'Answer: {response[\"answer\"]}')\n",
    "logger.info(f'Sources: {response[\"sources\"]}')\n",
    "\n",
    "sources = set(response['sources'].split(', '))\n",
    "\n",
    "for doc in response['source_documents']:\n",
    "    if doc.metadata[\"source\"] in sources:\n",
    "        logger.info(f'URL: {doc.metadata[\"source\"]}\\n')\n",
    "        logger.info(f'Source: {doc.page_content}\\n')\n",
    "        logger.info('=====================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://eugeneyan.com/writing/content-moderation/']"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['sources'].split(', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='How to Write: Advice from David Perell and Sahil Lavingia\\neugeneyan\\nStart Here\\nWriting\\nSpeaking\\nNewsletter\\nAbout\\nHow to Write: Advice from David Perell and Sahil Lavingia\\n[\\nwriting\\n]\\n· 4 min read\\nWriting is a superpower. Telepathy to be exact.\\nThink about it—through writing, I broadcast ideas from my mind to yours. Across time. Across space. (Yes, the internet plays a big role, but let’s focus on writing.) The more effective your writing, the stronger your telepathic ability.\\nWhy write about writing on this site?\\nWriting is essential for effective data science. Good writing means you get buy-in on ideas, your methodology and experiments can be replicated, and readers understand enough to give feedback. Poor writing gets you zilch (and snores). Business folk have enough trouble understanding data geeks as it is—don’t make it harder with your writing.\\nWriting is an important way to learn. (The other important way is learning.) When writing, you have to organize ideas and prune the unnecessary. Along the way, you find gaps in your understanding, which leads you to more research and learning.\\nWriting becomes more important as your career progresses. Everything is writing—emails, specs, documentation, articles. Code too. As you become more senior, you write more docs, less code. Seniors contribute by designing systems and communicating them to teams to implement.', lookup_str='', metadata={'source': 'https://eugeneyan.com/writing/how-to-write-david-x-sahil/'}, lookup_index=0)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinecone.init(api_key=os.getenv('PINECONE_API_KEY'), environment=PINECONE_ENV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {},\n",
       " 'total_vector_count': 0}"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_name = 'ask-ey'\n",
    "index = pinecone.Index(index_name)\n",
    "\n",
    "# Delete and recreate index\n",
    "# pinecone.delete_index(index_name)\n",
    "pinecone.create_index(index_name, dimension=1536, metric='cosine', pod_type='p2.x1')\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize with small set of data - \n",
    "# p = Pinecone.from_texts(docs[0:2], \n",
    "#                         embeddings, \n",
    "#                         index_name=index_name, \n",
    "#                         metadatas=metadata[0:2])\n",
    "\n",
    "# index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {},\n",
       " 'total_vector_count': 0}"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# Load existing pinecone index\n",
    "store = Pinecone.from_existing_index(index_name=index_name, embedding=embeddings)\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-26 17:21:12,696 - Adding chunk 1 of 10 (0 to 100))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5874d629b824f268bc671c93796fb3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upserted vectors:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-26 17:21:38,225 - Adding chunk 2 of 10 (100 to 200))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdda4ae1574e411aa66fe5d1ad6c5e5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upserted vectors:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-26 17:21:58,889 - Adding chunk 3 of 10 (200 to 300))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5af701e6ce24426badc48a11fa953c53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upserted vectors:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-26 17:22:17,041 - Adding chunk 4 of 10 (300 to 400))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc9a0089aa89405ebd7aed48b37777e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upserted vectors:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-26 17:22:39,901 - Adding chunk 5 of 10 (400 to 500))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6acf5cf5d6014984bf6c5f1bd4c395dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upserted vectors:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-26 17:22:58,653 - Adding chunk 6 of 10 (500 to 600))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "545244f0a9a74126a0143833d626290b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upserted vectors:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-26 17:23:19,250 - Adding chunk 7 of 10 (600 to 700))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7a3e718b72c481b87d590b7fe63a300",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upserted vectors:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-26 17:23:40,646 - Adding chunk 8 of 10 (700 to 800))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edeb1e11eb8148e7b301d9f5687f6a3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upserted vectors:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-26 17:23:58,679 - Adding chunk 9 of 10 (800 to 900))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e07fa7c925934611a81de348f8768209",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upserted vectors:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-26 17:24:18,642 - Adding chunk 10 of 10 (900 to 1000))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d531e75e24ed444ab075c541f0678d91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upserted vectors:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Add data to pinecone in chunks to avoid errors\n",
    "chunk_size = 100\n",
    "last_chunk = 0\n",
    "num_chunks = math.ceil(len(docs) / chunk_size)\n",
    "\n",
    "for i in range(last_chunk, num_chunks):    \n",
    "    start_idx = i * chunk_size \n",
    "    end_idx = min(start_idx + chunk_size, len(docs))\n",
    "    logger.info(f'Adding chunk {i+1} of {num_chunks} ({start_idx} to {end_idx}))')\n",
    "    \n",
    "    _docs = docs[start_idx:end_idx]\n",
    "    _metadata = metadata[start_idx:end_idx]\n",
    "    \n",
    "    store.add_texts(_docs, _metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {'': {'vector_count': 1000}},\n",
       " 'total_vector_count': 1000}"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this instead of load_qa_with_sources_chain for more control\n",
    "question = 'Question for eugeneyan.com: Why is writing important?'\n",
    "\n",
    "store = Pinecone.from_existing_index(index_name=index_name, embedding=embeddings)\n",
    "\n",
    "llm=OpenAI(temperature=0)\n",
    "chain = RetrievalQAWithSourcesChain.from_chain_type(llm, chain_type='stuff', retriever=store.as_retriever(), return_source_documents=True)\n",
    "response = chain({'question': question}, return_only_outputs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Question for eugeneyan.com: Why is writing important?',\n",
       " 'answer': ' Writing is important because it helps to clarify thinking, further learning, and share ideas with others.\\n',\n",
       " 'sources': 'https://eugeneyan.com/writing/how-to-write-david-x-sahil/, https://eugeneyan.com/writing/informal-mentors-chip-huyen/, https://eugeneyan.com/writing/writing-and-coding/, https://eugeneyan.com/writing/reading-note-taking-writing/',\n",
       " 'source_documents': [Document(page_content='“There’s no such thing as good writing, only good rewriting” - Robert Graves\\nWrite evergreen content. Focus on topics that will always add value and be helpful. Perhaps a short essay on why and how to write. Such writing stays relevant for years. (Nonetheless, many people write such pieces, so you might not contribute much. But hey, you learn a lot by writing about it). So reconsider writing that 183,768th piece of COVID-19 visualisation/dashboarding.\\nIf you found this post useful, share this viral tweet with your friends. Spread the word on writing effectively. =)\\n14 Ideas on How to Grow Your Business by Writing (THREAD) Ideas are all from @shl and @david_perellNotes below 👇https://t.co/c3Q45CZtdP\\nThanks to Yang Xinyi and Marianne Tan for reading drafts of this.', lookup_str='', metadata={'source': 'https://eugeneyan.com/writing/how-to-write-david-x-sahil/'}, lookup_index=0),\n",
       "  Document(page_content='I think one of the biggest challenges is ensuring that AI is doing more good than evil. Historically, technological progresses have allowed those with technology to oppress those who don’t. For example, the industrial revolution allowed many European nations to grow, but it also allowed them to colonize smaller, lesser developed countries. Now, we see that some countries are very good at AI; I’m concerned something similar could happen again.\\n(Author’s note: Most ML advancements and capabilities lie within a handful of tech giants. I wonder how we can help smaller companies also benefit from machine learning.)\\nHmmm, this is a hard question.\\nFor me, I like fundamental ideas. I like best practices. There’s a saying I like: “Innovate where you can. Where you can’t, use the industry standards.” For SMEs, instead of chasing fancy new things, I think they should choose less fancy but more stable solutions.\\nMany enterprises have already seen some benefits from AI. I think it’s important for SMEs to consider ML solutions, and it’s good to start simple.\\nI mostly learn through hands-on experience, including work. At work, I learn a lot from my colleagues, who are awesome and very patient with me. I also enjoy reading books and think that books have less noise relative to what’s available online.\\nI also try to write about what I learned. Writing helps me learn better.', lookup_str='', metadata={'source': 'https://eugeneyan.com/writing/informal-mentors-chip-huyen/'}, lookup_index=0),\n",
       "  Document(page_content='Here’s a good question to ask ourselves: “Which would have greater impact right now?” If we need to understand and clarify the intent and context so we can start implementing, then writing a design doc will help most. If we’re struggling to meet an delivery deadline, then writing (and reviewing) code will help more.\\nWriting documents is like writing code. Code is for machines; documents are for people.\\nWriting documents is hard. For some, harder than writing code. And relative to writing code, the impact of writing documents is not as immediately measurable. But if it helps provide clarity, or save the team time, then it’s well worth the effort. (If you know of ways to measure the impact of writing, I would love to hear from you!)\\nWhat advice do you have for tech professionals starting to write more? Share in the comments below.\\nWhy does writing become more important (than coding) as we gain seniority? How do we balance between both? How can we help the team write better?Here, I explore answers to these question with the help of some friends, including @Al_Grigor & @nlpguy_.https://t.co/foqhU5A9Rx\\nThanks to Yang Xinyi and Drew Stegmaier for reading drafts of this. Thanks to David Said, Alexey Grigorev, Pratik Bhavsar, and Grace Tang for making time to discuss on this topic.', lookup_str='', metadata={'source': 'https://eugeneyan.com/writing/writing-and-coding/'}, lookup_index=0),\n",
       "  Document(page_content='Here’s a good question to ask ourselves: “Which would have greater impact right now?” If we need to understand and clarify the intent and context so we can start implementing, then writing a design doc will help most. If we’re struggling to meet an delivery deadline, then writing (and reviewing) code will help more.\\nWriting documents is like writing code. Code is for machines; documents are for people.\\nWriting documents is hard. For some, harder than writing code. And relative to writing code, the impact of writing documents is not as immediately measurable. But if it helps provide clarity, or save the team time, then it’s well worth the effort. (If you know of ways to measure the impact of writing, I would love to hear from you!)\\nWhat advice do you have for tech professionals starting to write more? Share in the comments below.\\nWhy does writing become more important (than coding) as we gain seniority? How do we balance between both? How can we help the team write better?Here, I explore answers to these question with the help of some friends, including @Al_Grigor & @nlpguy_.https://t.co/foqhU5A9Rx\\nThanks to Yang Xinyi and Drew Stegmaier for reading drafts of this. Thanks to David Said, Alexey Grigorev, Pratik Bhavsar, and Grace Tang for making time to discuss on this topic.', lookup_str='', metadata={'source': 'https://eugeneyan.com/writing/writing-and-coding/'}, lookup_index=0),\n",
       "  Document(page_content='Writing begins before you write. I used to think writing started with the first sentence typed. I was wrong.\\nIt should be clear from previous sections that writing starts with reading and taking notes, similar to how you would write an academic paper. (I hope you vaguely recall the process of writing papers in college). Don’t start with only a blank sheet of paper.\\nWriting is not the outcome of thinking—it is thinking. Ever wondered why writing is hard? It’s because you have to think hard.\\nBefore writing, I reviewed my notes and knowledge tree on the relevant material. While writing, I discovered gaps in my understanding. This led to more research and learning. After a first draft, I had to organise the ideas, prune the unnecessary, and edit the language to ensure my thoughts are conveyed correctly.\\nThrough this, I clarified my thinking and furthered my learning. As a bonus, I now have an essay that can be shared easily. Others can read it to understand my views and provide feedback.\\nReading, taking notes, and writing are not separate activities—they make up a (virtuous) cycle. As you write, you discover more you need to read and learn.\\nTry it. The next time you read (non-fiction), consciously think about how to take notes and teach someone else the material. The next time you write, use your notes to put together an outline, upon which you can add your ideas and views.\\nThanks to Yang Xinyi, Gabriel Chuan, and Marianne Tan for reading drafts of this.', lookup_str='', metadata={'source': 'https://eugeneyan.com/writing/reading-note-taking-writing/'}, lookup_index=0)]}"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_list = []\n",
    "pretty_qa = ''\n",
    "\n",
    "pretty_qa += f'**Question:** {response[\"question\"]}\\n'\n",
    "pretty_qa += f'**Answer:** {response[\"answer\"]}\\n'\n",
    "pretty_qa += f'**Sources:** {response[\"sources\"]}\\n\\n'\n",
    "result_list.append(pretty_qa)\n",
    "\n",
    "for doc in response['source_documents']:\n",
    "    pretty_source = ''\n",
    "    pretty_source += f'**Source:** {doc.page_content}\\n'\n",
    "    pretty_source += f'**URL:** {doc.metadata[\"source\"]}\\n\\n'\n",
    "    result_list.append(pretty_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Question for eugeneyan.com: Why is writing important?\n",
      "Answer:  Writing is important because it helps to clarify thinking, further learning, and share ideas with others.\n",
      "\n",
      "Sources: https://eugeneyan.com/writing/how-to-write-david-x-sahil/, https://eugeneyan.com/writing/informal-mentors-chip-huyen/, https://eugeneyan.com/writing/writing-and-coding/, https://eugeneyan.com/writing/reading-note-taking-writing/\n",
      "\n",
      "Source: “There’s no such thing as good writing, only good rewriting” - Robert Graves\n",
      "Write evergreen content. Focus on topics that will always add value and be helpful. Perhaps a short essay on why and how to write. Such writing stays relevant for years. (Nonetheless, many people write such pieces, so you might not contribute much. But hey, you learn a lot by writing about it). So reconsider writing that 183,768th piece of COVID-19 visualisation/dashboarding.\n",
      "If you found this post useful, share this viral tweet with your friends. Spread the word on writing effectively. =)\n",
      "14 Ideas on How to Grow Your Business by Writing (THREAD) Ideas are all from @shl and @david_perellNotes below 👇https://t.co/c3Q45CZtdP\n",
      "Thanks to Yang Xinyi and Marianne Tan for reading drafts of this.\n",
      "URL: https://eugeneyan.com/writing/how-to-write-david-x-sahil/\n",
      "\n",
      "Source: I think one of the biggest challenges is ensuring that AI is doing more good than evil. Historically, technological progresses have allowed those with technology to oppress those who don’t. For example, the industrial revolution allowed many European nations to grow, but it also allowed them to colonize smaller, lesser developed countries. Now, we see that some countries are very good at AI; I’m concerned something similar could happen again.\n",
      "(Author’s note: Most ML advancements and capabilities lie within a handful of tech giants. I wonder how we can help smaller companies also benefit from machine learning.)\n",
      "Hmmm, this is a hard question.\n",
      "For me, I like fundamental ideas. I like best practices. There’s a saying I like: “Innovate where you can. Where you can’t, use the industry standards.” For SMEs, instead of chasing fancy new things, I think they should choose less fancy but more stable solutions.\n",
      "Many enterprises have already seen some benefits from AI. I think it’s important for SMEs to consider ML solutions, and it’s good to start simple.\n",
      "I mostly learn through hands-on experience, including work. At work, I learn a lot from my colleagues, who are awesome and very patient with me. I also enjoy reading books and think that books have less noise relative to what’s available online.\n",
      "I also try to write about what I learned. Writing helps me learn better.\n",
      "URL: https://eugeneyan.com/writing/informal-mentors-chip-huyen/\n",
      "\n",
      "Source: Here’s a good question to ask ourselves: “Which would have greater impact right now?” If we need to understand and clarify the intent and context so we can start implementing, then writing a design doc will help most. If we’re struggling to meet an delivery deadline, then writing (and reviewing) code will help more.\n",
      "Writing documents is like writing code. Code is for machines; documents are for people.\n",
      "Writing documents is hard. For some, harder than writing code. And relative to writing code, the impact of writing documents is not as immediately measurable. But if it helps provide clarity, or save the team time, then it’s well worth the effort. (If you know of ways to measure the impact of writing, I would love to hear from you!)\n",
      "What advice do you have for tech professionals starting to write more? Share in the comments below.\n",
      "Why does writing become more important (than coding) as we gain seniority? How do we balance between both? How can we help the team write better?Here, I explore answers to these question with the help of some friends, including @Al_Grigor & @nlpguy_.https://t.co/foqhU5A9Rx\n",
      "Thanks to Yang Xinyi and Drew Stegmaier for reading drafts of this. Thanks to David Said, Alexey Grigorev, Pratik Bhavsar, and Grace Tang for making time to discuss on this topic.\n",
      "URL: https://eugeneyan.com/writing/writing-and-coding/\n",
      "\n",
      "Source: Here’s a good question to ask ourselves: “Which would have greater impact right now?” If we need to understand and clarify the intent and context so we can start implementing, then writing a design doc will help most. If we’re struggling to meet an delivery deadline, then writing (and reviewing) code will help more.\n",
      "Writing documents is like writing code. Code is for machines; documents are for people.\n",
      "Writing documents is hard. For some, harder than writing code. And relative to writing code, the impact of writing documents is not as immediately measurable. But if it helps provide clarity, or save the team time, then it’s well worth the effort. (If you know of ways to measure the impact of writing, I would love to hear from you!)\n",
      "What advice do you have for tech professionals starting to write more? Share in the comments below.\n",
      "Why does writing become more important (than coding) as we gain seniority? How do we balance between both? How can we help the team write better?Here, I explore answers to these question with the help of some friends, including @Al_Grigor & @nlpguy_.https://t.co/foqhU5A9Rx\n",
      "Thanks to Yang Xinyi and Drew Stegmaier for reading drafts of this. Thanks to David Said, Alexey Grigorev, Pratik Bhavsar, and Grace Tang for making time to discuss on this topic.\n",
      "URL: https://eugeneyan.com/writing/writing-and-coding/\n",
      "\n",
      "Source: Writing begins before you write. I used to think writing started with the first sentence typed. I was wrong.\n",
      "It should be clear from previous sections that writing starts with reading and taking notes, similar to how you would write an academic paper. (I hope you vaguely recall the process of writing papers in college). Don’t start with only a blank sheet of paper.\n",
      "Writing is not the outcome of thinking—it is thinking. Ever wondered why writing is hard? It’s because you have to think hard.\n",
      "Before writing, I reviewed my notes and knowledge tree on the relevant material. While writing, I discovered gaps in my understanding. This led to more research and learning. After a first draft, I had to organise the ideas, prune the unnecessary, and edit the language to ensure my thoughts are conveyed correctly.\n",
      "Through this, I clarified my thinking and furthered my learning. As a bonus, I now have an essay that can be shared easily. Others can read it to understand my views and provide feedback.\n",
      "Reading, taking notes, and writing are not separate activities—they make up a (virtuous) cycle. As you write, you discover more you need to read and learn.\n",
      "Try it. The next time you read (non-fiction), consciously think about how to take notes and teach someone else the material. The next time you write, use your notes to put together an outline, upon which you can add your ideas and views.\n",
      "Thanks to Yang Xinyi, Gabriel Chuan, and Marianne Tan for reading drafts of this.\n",
      "URL: https://eugeneyan.com/writing/reading-note-taking-writing/\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(pretty_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-26 17:28:06,037 - Question: Question for eugeneyan.com: Why is writing important?\n",
      "2023-03-26 17:28:06,038 - Answer:  Writing is important because it helps to clarify thinking, further learning, and share ideas with others.\n",
      "\n",
      "2023-03-26 17:28:06,039 - Sources: https://eugeneyan.com/writing/how-to-write-david-x-sahil/, https://eugeneyan.com/writing/informal-mentors-chip-huyen/, https://eugeneyan.com/writing/writing-and-coding/, https://eugeneyan.com/writing/reading-note-taking-writing/\n",
      "2023-03-26 17:28:06,040 - URL: https://eugeneyan.com/writing/how-to-write-david-x-sahil/\n",
      "\n",
      "2023-03-26 17:28:06,040 - Source: “There’s no such thing as good writing, only good rewriting” - Robert Graves\n",
      "Write evergreen content. Focus on topics that will always add value and be helpful. Perhaps a short essay on why and how to write. Such writing stays relevant for years. (Nonetheless, many people write such pieces, so you might not contribute much. But hey, you learn a lot by writing about it). So reconsider writing that 183,768th piece of COVID-19 visualisation/dashboarding.\n",
      "If you found this post useful, share this viral tweet with your friends. Spread the word on writing effectively. =)\n",
      "14 Ideas on How to Grow Your Business by Writing (THREAD) Ideas are all from @shl and @david_perellNotes below 👇https://t.co/c3Q45CZtdP\n",
      "Thanks to Yang Xinyi and Marianne Tan for reading drafts of this.\n",
      "\n",
      "2023-03-26 17:28:06,041 - =====================\n",
      "2023-03-26 17:28:06,042 - URL: https://eugeneyan.com/writing/informal-mentors-chip-huyen/\n",
      "\n",
      "2023-03-26 17:28:06,042 - Source: I think one of the biggest challenges is ensuring that AI is doing more good than evil. Historically, technological progresses have allowed those with technology to oppress those who don’t. For example, the industrial revolution allowed many European nations to grow, but it also allowed them to colonize smaller, lesser developed countries. Now, we see that some countries are very good at AI; I’m concerned something similar could happen again.\n",
      "(Author’s note: Most ML advancements and capabilities lie within a handful of tech giants. I wonder how we can help smaller companies also benefit from machine learning.)\n",
      "Hmmm, this is a hard question.\n",
      "For me, I like fundamental ideas. I like best practices. There’s a saying I like: “Innovate where you can. Where you can’t, use the industry standards.” For SMEs, instead of chasing fancy new things, I think they should choose less fancy but more stable solutions.\n",
      "Many enterprises have already seen some benefits from AI. I think it’s important for SMEs to consider ML solutions, and it’s good to start simple.\n",
      "I mostly learn through hands-on experience, including work. At work, I learn a lot from my colleagues, who are awesome and very patient with me. I also enjoy reading books and think that books have less noise relative to what’s available online.\n",
      "I also try to write about what I learned. Writing helps me learn better.\n",
      "\n",
      "2023-03-26 17:28:06,043 - =====================\n",
      "2023-03-26 17:28:06,043 - URL: https://eugeneyan.com/writing/writing-and-coding/\n",
      "\n",
      "2023-03-26 17:28:06,044 - Source: Here’s a good question to ask ourselves: “Which would have greater impact right now?” If we need to understand and clarify the intent and context so we can start implementing, then writing a design doc will help most. If we’re struggling to meet an delivery deadline, then writing (and reviewing) code will help more.\n",
      "Writing documents is like writing code. Code is for machines; documents are for people.\n",
      "Writing documents is hard. For some, harder than writing code. And relative to writing code, the impact of writing documents is not as immediately measurable. But if it helps provide clarity, or save the team time, then it’s well worth the effort. (If you know of ways to measure the impact of writing, I would love to hear from you!)\n",
      "What advice do you have for tech professionals starting to write more? Share in the comments below.\n",
      "Why does writing become more important (than coding) as we gain seniority? How do we balance between both? How can we help the team write better?Here, I explore answers to these question with the help of some friends, including @Al_Grigor & @nlpguy_.https://t.co/foqhU5A9Rx\n",
      "Thanks to Yang Xinyi and Drew Stegmaier for reading drafts of this. Thanks to David Said, Alexey Grigorev, Pratik Bhavsar, and Grace Tang for making time to discuss on this topic.\n",
      "\n",
      "2023-03-26 17:28:06,045 - =====================\n",
      "2023-03-26 17:28:06,045 - URL: https://eugeneyan.com/writing/writing-and-coding/\n",
      "\n",
      "2023-03-26 17:28:06,046 - Source: Here’s a good question to ask ourselves: “Which would have greater impact right now?” If we need to understand and clarify the intent and context so we can start implementing, then writing a design doc will help most. If we’re struggling to meet an delivery deadline, then writing (and reviewing) code will help more.\n",
      "Writing documents is like writing code. Code is for machines; documents are for people.\n",
      "Writing documents is hard. For some, harder than writing code. And relative to writing code, the impact of writing documents is not as immediately measurable. But if it helps provide clarity, or save the team time, then it’s well worth the effort. (If you know of ways to measure the impact of writing, I would love to hear from you!)\n",
      "What advice do you have for tech professionals starting to write more? Share in the comments below.\n",
      "Why does writing become more important (than coding) as we gain seniority? How do we balance between both? How can we help the team write better?Here, I explore answers to these question with the help of some friends, including @Al_Grigor & @nlpguy_.https://t.co/foqhU5A9Rx\n",
      "Thanks to Yang Xinyi and Drew Stegmaier for reading drafts of this. Thanks to David Said, Alexey Grigorev, Pratik Bhavsar, and Grace Tang for making time to discuss on this topic.\n",
      "\n",
      "2023-03-26 17:28:06,047 - =====================\n",
      "2023-03-26 17:28:06,047 - URL: https://eugeneyan.com/writing/reading-note-taking-writing/\n",
      "\n",
      "2023-03-26 17:28:06,048 - Source: Writing begins before you write. I used to think writing started with the first sentence typed. I was wrong.\n",
      "It should be clear from previous sections that writing starts with reading and taking notes, similar to how you would write an academic paper. (I hope you vaguely recall the process of writing papers in college). Don’t start with only a blank sheet of paper.\n",
      "Writing is not the outcome of thinking—it is thinking. Ever wondered why writing is hard? It’s because you have to think hard.\n",
      "Before writing, I reviewed my notes and knowledge tree on the relevant material. While writing, I discovered gaps in my understanding. This led to more research and learning. After a first draft, I had to organise the ideas, prune the unnecessary, and edit the language to ensure my thoughts are conveyed correctly.\n",
      "Through this, I clarified my thinking and furthered my learning. As a bonus, I now have an essay that can be shared easily. Others can read it to understand my views and provide feedback.\n",
      "Reading, taking notes, and writing are not separate activities—they make up a (virtuous) cycle. As you write, you discover more you need to read and learn.\n",
      "Try it. The next time you read (non-fiction), consciously think about how to take notes and teach someone else the material. The next time you write, use your notes to put together an outline, upon which you can add your ideas and views.\n",
      "Thanks to Yang Xinyi, Gabriel Chuan, and Marianne Tan for reading drafts of this.\n",
      "\n",
      "2023-03-26 17:28:06,049 - =====================\n"
     ]
    }
   ],
   "source": [
    "logger.info(f'Question: {response[\"question\"]}')\n",
    "logger.info(f'Answer: {response[\"answer\"]}')\n",
    "logger.info(f'Sources: {response[\"sources\"]}')\n",
    "\n",
    "sources = set(response['sources'].split(', '))\n",
    "\n",
    "for doc in response['source_documents']:\n",
    "    if doc.metadata[\"source\"] in sources:\n",
    "        logger.info(f'URL: {doc.metadata[\"source\"]}\\n')\n",
    "        logger.info(f'Source: {doc.page_content}\\n')\n",
    "        logger.info('=====================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
